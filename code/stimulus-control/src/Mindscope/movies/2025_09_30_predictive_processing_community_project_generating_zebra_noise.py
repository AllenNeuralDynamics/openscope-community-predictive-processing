# -*- coding: utf-8 -*-
"""2025-09-30-Predictive processing community project - Generating zebra noise.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18vYfYtk4vAszFVMMzC1aq-Zw5rZ2dq7O
"""

!pip install "git+https://github.com/mwshinn/zebra_noise@master"

import zebranoise

"""We will use the code used in https://www.biorxiv.org/content/10.1101/2025.07.19.665666v1

Per the manuscript: "Visual
stimuli were displayed at 30 Hz on two screens placed at 90 degrees
in front and on the left side of the head-fixed animal, covering the
range of -135 to 45 deg of azimuth and -35 to 35 deg of elevation."

The two screens were 10 cm from the mouse and were each 16cm height and 20 cm width.

The author noted that the pixels were not perfectly square. The generated movie was stretched to fill across both screens fully (Hence the zebra noise is 4:3 whereas the screens are 5:4).

Stimuli were not spherically warped so perceived spatial frequency could vary depending on gaze given the projection of a flat screen onto a sphere. We will focus on the center location, at 10cm.

"""

# Generate a short test stimulus
print("Generating UCL zebranoise...")
zebranoise.zebra_noise("ucl_screen.mp4", xsize=1602, ysize=600, tdur=5, levels=10, xyscale=.2, tscale=50,fps=30, seed=0)

from IPython.display import Video
Video("ucl_screen.mp4", embed=True)

"""The Allen Institute screen is covering 120 deg horizontally and 95 deg vertically. It is positioned 15cm away from the eye. Our stimuli are typically spherically warped directly by Python/Bonsai

We will apply spherical warping. However we do want to maintain a similar perception of spatial frequency at the center of the screen regardless of the changing geometry.

The right way to do this is to translate in degrees. The Zebra_noise package generates movies as large as the provided pixel size: ie. increasing pixels keep the same spatial noise relationship and add additional surrounding waves. This means it essentially operates in degrees space. More pixels->Larger degrees coverage.

To be mindful of the original non-square pixel size, let's just tranlate the horizontal degrees coverage and use our screen ratio to create the vertical dimension.

The UCL set-up is covering 180 deg. The Allen's is covering 120 deg. So we need to cut a smaller portion of the zebra noise.
"""

1602*120/180

"""Our screen covers 95 deg vertically so along the vertical dimension our movies needs to be:

"""

95/120*1068

"""Because our screen is 15cm away, the zebra pattern needs to be scaled up, essentially 50%.
This is done by applying  xscale=1.5, yscale=1.5 to the original function. The pattern will appear zoomed in because our screen is further away and we want to maintain the same perceived size.

Here is therefore the code to generate the corresponding Allen Instute movie to be displayed full screen with warping
"""

# Generate a short test stimulus
print("Generating allen institute zebranoise...")
zebranoise.zebra_noise("allen_screen.mp4", xsize=1068, ysize=845, tdur=200/30, levels=10, xyscale=.2, tscale=50,fps=30, seed=0, xscale=1.5, yscale=1.5)

from IPython.display import Video
Video("allen_screen.mp4", embed=True)

"""Given that the stimulus in the UCL was not spherically wraped, it is likely that a range of spatial frequencies were presented across V1. Our stimuli are meant to be used with recordings in visual areas centers so we should focus on this subset of the stimulus. To get to the range of meaningful spatial frequency, a good way to do this is to extract the spatial fourier transform."""

import imageio
video_reader = imageio.get_reader("/content/allen_screen.mp4")

"""## Compute fourier transform


"""

from scipy.fft import fft2
import numpy as np

# Initialize a variable to store the sum of magnitude spectra
sum_magnitude_spectrum = None
num_frames = 0

for i, frame in enumerate(video_reader):
    # Convert frame to grayscale (assuming frame is RGB or RGBA)
    if frame.ndim == 3:
        grayscale_frame = np.mean(frame, axis=2)
    else:
        grayscale_frame = frame # Already grayscale

    # Compute 2D Fourier transform
    f_transform = fft2(grayscale_frame)

    # Shift the zero-frequency component to the center
    f_transform_shifted = np.fft.fftshift(f_transform)

    # Get the magnitude spectrum
    magnitude_spectrum = np.abs(f_transform_shifted)

    # Add the magnitude spectrum to the sum
    if sum_magnitude_spectrum is None:
        sum_magnitude_spectrum = magnitude_spectrum
    else:
        sum_magnitude_spectrum += magnitude_spectrum

    num_frames += 1

# Compute the average magnitude spectrum
average_magnitude_spectrum = sum_magnitude_spectrum / num_frames

print(f"Processed {num_frames} frames and computed the average magnitude spectrum.")

# Calculate spatial frequencies
rows, cols = average_magnitude_spectrum.shape
spatial_freq_rows = np.fft.fftfreq(rows)
spatial_freq_cols = np.fft.fftfreq(cols)

print("Shape of average magnitude spectrum:", average_magnitude_spectrum.shape)

import matplotlib.pyplot as plt
import numpy as np

# Assuming screen is 15cm away and spherically warped
# Convert pixel frequencies to degrees
screen_distance_cm = 15
# To convert from pixels to degrees, we need the pixel size in cm and the screen distance.
# We don't have the pixel size directly, but we know the screen covers 120 degrees horizontally
# and has 1072 pixels horizontally.
# So, the degrees per pixel is 120 / 1072 degrees/pixel.
degrees_per_pixel_h = 120 / cols # Use the 'cols' variable from the notebook state
degrees_per_pixel_v = 95 / rows # Use the 'rows' variable from the notebook state

# Calculate spatial frequencies in cycles per degree
# The frequency in cycles/pixel is obtained from the fftfreq output (which is in 1/pixels)
# To get cycles/degree, we multiply by pixels/degree which is the inverse of degrees/pixel
spatial_freq_h_cpd = spatial_freq_cols / degrees_per_pixel_h
spatial_freq_v_cpd = spatial_freq_rows / degrees_per_pixel_v

# Create meshgrid for plotting
h_freqs, v_freqs = np.meshgrid(spatial_freq_h_cpd, spatial_freq_v_cpd)

plt.figure(figsize=(10, 8))
# Use the spatial frequencies in cycles per degree for the extent
plt.imshow(np.log(average_magnitude_spectrum + 1), extent=[np.min(spatial_freq_h_cpd), np.max(spatial_freq_h_cpd), np.min(spatial_freq_v_cpd), np.max(spatial_freq_v_cpd)],
           aspect='auto') # Set aspect to auto to avoid stretching/squishing the image based on the new extent
plt.colorbar(label='log(Magnitude + 1)')
plt.title('Average Magnitude Spectrum of Spatial Frequencies (cycles/degree)')
plt.xlabel('Horizontal Frequency (cycles/degree)')
plt.ylabel('Vertical Frequency (cycles/degree)')
plt.show()

"""Next we want to convert this 2D spatial fourier transform into a radial transform as our stimuli are meant to be isotropic.

We first define re-usable functions to do this processs more systematically
"""

def process_and_average_spectrum(video_path):
    """
    Processes a video file, computes the average magnitude spectrum of the
    spatial Fourier transform for each frame, and excludes horizontal and
    vertical frequency components (except DC).

    Args:
        video_path (str): The path to the video file.

    Returns:
        tuple: A tuple containing:
            - average_magnitude_spectrum (np.ndarray): The average magnitude
                                                      spectrum across frames.
            - exclude_axes_mask (np.ndarray): A boolean mask to exclude horizontal
                                            and vertical axes (excluding DC).
            - rows (int): The number of rows (height) of the video frames.
            - cols (int): The number of columns (width) of the video frames.
    """
    video_reader = imageio.get_reader(video_path)

    sum_magnitude_spectrum = None
    num_frames = 0

    # Get the shape of the first frame
    first_frame = video_reader.get_data(0)
    rows, cols = first_frame.shape[:2]

    # Calculate the center of the spectrum for excluding axes
    center_row, center_col = rows // 2, cols // 2

    # Create index arrays for identifying axes
    row_indices, col_indices = np.indices((rows, cols))

    for i, frame in enumerate(video_reader):
        # Convert frame to grayscale
        if frame.ndim == 3:
            grayscale_frame = np.mean(frame, axis=2)
        else:
            grayscale_frame = frame

        # Compute 2D Fourier transform
        f_transform = fft2(grayscale_frame)

        # Shift the zero-frequency component to the center
        f_transform_shifted = np.fft.fftshift(f_transform)

        # Get the magnitude spectrum
        magnitude_spectrum = np.abs(f_transform_shifted)

        # Add the magnitude spectrum to the sum
        if sum_magnitude_spectrum is None:
            sum_magnitude_spectrum = magnitude_spectrum
        else:
            sum_magnitude_spectrum += magnitude_spectrum

        num_frames += 1

    # Compute the average magnitude spectrum
    average_magnitude_spectrum = sum_magnitude_spectrum / num_frames

    # Identify indices corresponding to the horizontal and vertical axes (excluding the DC component)
    horizontal_axis_indices = (row_indices == center_row) & (col_indices != center_col)
    vertical_axis_indices = (col_indices == center_col) & (row_indices != center_row)

    # Combine the horizontal and vertical axis indices
    axes_indices = horizontal_axis_indices | vertical_axis_indices

    # Create a mask to exclude the horizontal and vertical axes (excluding DC)
    exclude_axes_mask = ~axes_indices.flatten()

    return average_magnitude_spectrum, exclude_axes_mask, rows, cols

print("Defined the function process_and_average_spectrum.")

def calculate_radial_average(radial_freq_cpd_filtered, average_magnitude_spectrum_filtered):
    """
    Calculates the 1D radial average of a filtered magnitude spectrum.

    Args:
        radial_freq_cpd_filtered (np.ndarray): Flattened array of radial frequencies
                                                in cycles per degree, with axes excluded.
        average_magnitude_spectrum_filtered (np.ndarray): Flattened array of magnitude
                                                        spectrum values, with axes excluded.

    Returns:
        tuple: A tuple containing:
            - bin_centers (np.ndarray): The center frequency of each bin.
            - average_magnitude_per_bin (np.ndarray): The average magnitude in each bin.
    """
    # Sort by radial frequency
    sorted_indices = np.argsort(radial_freq_cpd_filtered)
    radial_freq_cpd_sorted = radial_freq_cpd_filtered[sorted_indices]
    average_magnitude_spectrum_sorted = average_magnitude_spectrum_filtered[sorted_indices]

    # Define frequency bins
    # Find the maximum frequency, excluding the DC component at 0
    # Ensure to handle the case where all frequencies are 0 (unlikely but good practice)
    non_zero_freqs = radial_freq_cpd_sorted[radial_freq_cpd_sorted > 0]
    if non_zero_freqs.size > 0:
        max_freq = np.max(non_zero_freqs)
        min_freq_for_log = np.min(non_zero_freqs)

        # Create log-spaced bins from a small value above 0 to the max frequency
        num_bins = 100 # Use the same number of bins as before
        bins = np.logspace(np.log10(min_freq_for_log), np.log10(max_freq), num_bins)
    else:
        # Handle the case where there are no non-zero frequencies
        return np.array([]), np.array([])


    # Use np.histogram to bin the magnitudes based on radial frequency
    # We will sum the magnitudes in each bin and also count the number of points in each bin
    magnitude_sum, bin_edges = np.histogram(radial_freq_cpd_sorted, bins=bins, weights=average_magnitude_spectrum_sorted)
    bin_counts, _ = np.histogram(radial_freq_cpd_sorted, bins=bins)

    # Avoid division by zero for empty bins
    average_magnitude_per_bin = np.where(bin_counts > 0, magnitude_sum / bin_counts, 0)

    # Calculate the center of each bin for plotting
    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0

    return bin_centers, average_magnitude_per_bin

print("Defined the function calculate_radial_average.")

# Calculate radial frequency
# Center of the spectrum
# rows, cols = average_magnitude_spectrum.shape
# center_row, center_col = rows // 2, cols // 2

# Create a meshgrid for pixel coordinates
# The row and column indices should be relative to the center for calculating radial distance
# We can create frequency arrays that are centered around zero
spatial_freq_rows_centered = np.fft.fftshift(spatial_freq_rows)
spatial_freq_cols_centered = np.fft.fftshift(spatial_freq_cols)


# Create 2D arrays of these centered frequency values using meshgrid
spatial_freq_cols_2d_centered, spatial_freq_rows_2d_centered = np.meshgrid(spatial_freq_cols_centered, spatial_freq_rows_centered)


# Calculate the radial frequency in cycles/pixel from the centered 2D frequency arrays
radial_freq_pixels = np.sqrt(spatial_freq_rows_2d_centered**2 + spatial_freq_cols_2d_centered**2)


# Convert radial frequency from cycles/pixel to cycles/degree
# Use the degrees_per_pixel_v and degrees_per_pixel_h variables already calculated
# We need to use the original unshifted spatial_freq_rows and spatial_freq_cols for this conversion
# as degrees_per_pixel is calculated based on the full range of frequencies
# However, the radial distance should be calculated from the centered frequencies.
# Let's recalculate degrees per pixel based on the centered frequencies and the dimensions.
# The total range of frequencies in cycles/pixel is from -max_freq to +max_freq.
# The number of degrees covered by this range is 120 horizontally and 95 vertically.
# So, degrees per cycle/pixel is 120 / (max_freq_h * 2) and 95 / (max_freq_v * 2)
# max_freq_h = np.max(np.abs(spatial_freq_cols))
# max_freq_v = np.max(np.abs(spatial_freq_rows))
# degrees_per_cycle_pixel_h = 120 / (max_freq_h * 2) if max_freq_h > 0 else 0
# degrees_per_cycle_pixel_v = 95 / (max_freq_v * 2) if max_freq_v > 0 else 0

# A simpler approach is to convert the centered frequencies to cycles per degree directly
radial_freq_cpd = np.sqrt((spatial_freq_rows_2d_centered / degrees_per_pixel_v)**2 + (spatial_freq_cols_2d_centered / degrees_per_pixel_h)**2)


# Flatten the radial frequencies and the average magnitude spectrum
radial_freq_cpd_flat = radial_freq_cpd.flatten()
average_magnitude_spectrum_flat = average_magnitude_spectrum.flatten()

# To get exclude_axes_mask, we need to call process_and_average_spectrum
# For this cell, we will call it with allen_screen.mp4 as an example
# In the later cell where we iterate through videos, we will call it within the loop
video_path_example = "/content/allen_screen.mp4" # Example video path
(average_magnitude_spectrum_example, exclude_axes_mask,
 rows_example, cols_example) = process_and_average_spectrum(video_path_example)

# Identify indices corresponding to the horizontal and vertical axes (excluding the DC component)
# These indices are relative to the centered spectrum
# We can get the indices from the example call
# row_indices = np.indices((rows_example, cols_example))[0]
# col_indices = np.indices((rows_example, cols_example))[1]
# horizontal_axis_indices = (row_indices == rows_example // 2) & (col_indices != cols_example // 2)
# vertical_axis_indices = (col_indices == cols_example // 2) & (row_indices != rows_example // 2)

# We already have the exclude_axes_mask from the function call, which is what we need
# exclude_axes_mask = exclude_axes_mask_example # Use the mask from the function output


# Apply the mask to the flattened arrays
radial_freq_cpd_filtered = radial_freq_cpd_flat[exclude_axes_mask]
average_magnitude_spectrum_filtered = average_magnitude_spectrum_flat[exclude_axes_mask]


# Sort by radial frequency
sorted_indices = np.argsort(radial_freq_cpd_filtered)
radial_freq_cpd_sorted = radial_freq_cpd_filtered[sorted_indices]
average_magnitude_spectrum_sorted = average_magnitude_spectrum_filtered[sorted_indices]

# Bin the data by radial frequency and average the magnitude
# Define frequency bins - you might need to adjust the bin edges based on your data
# Let's create bins that are equally spaced in log-space for better visualization of a wide range of frequencies
# Find the maximum frequency, excluding the DC component at 0
max_freq = np.max(radial_freq_cpd_sorted[radial_freq_cpd_sorted > 0])
# Create log-spaced bins from a small value above 0 to the max frequency
num_bins = 100
# Create log-spaced bins from a small value above 0 to the max frequency
# Ensure the starting bin edge is greater than 0 if using logspace
min_freq_for_log = np.min(radial_freq_cpd_sorted[radial_freq_cpd_sorted > 0])
if min_freq_for_log == 0:
    # If the smallest non-zero frequency is 0, adjust the start of logspace
    bins = np.logspace(np.log10(np.finfo(float).eps), np.log10(max_freq), num_bins)
else:
    bins = np.logspace(np.log10(min_freq_for_log), np.log10(max_freq), num_bins)


# Use np.histogram to bin the magnitudes based on radial frequency
# We will sum the magnitudes in each bin and also count the number of points in each bin
magnitude_sum, bin_edges = np.histogram(radial_freq_cpd_sorted, bins=bins, weights=average_magnitude_spectrum_sorted)
bin_counts, _ = np.histogram(radial_freq_cpd_sorted, bins=bins)

# Avoid division by zero for empty bins
average_magnitude_per_bin = np.where(bin_counts > 0, magnitude_sum / bin_counts, 0)

# Calculate the center of each bin for plotting
bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0

# Plot the averaged magnitude spectrum
plt.figure(figsize=(10, 6))
plt.plot(bin_centers, average_magnitude_per_bin, 'r.')
plt.yscale('log') # Use a log scale for the magnitude axis
plt.xlabel('Spatial Frequency (cycles/degree)')
plt.ylabel('Average Magnitude')
plt.title('Average Magnitude Spectrum vs. Spatial Frequency (Isotropic, excluding axes)')
# Remove or adjust the x-axis limits to show the entire plot
plt.xlim([bins[0], bins[-1]]) # Set the x-axis limits from the start of the first bin to the end of the last bin

plt.show()

"""We want to check the fourier transform for various values of xscale and yscale

"""

import numpy as np
scale_values = np.linspace(0.6, 1.4, 5).tolist()
print(scale_values)

"""## Generate videos with varying scale

Iterate through the list of scale values and generate a zebra noise video for each scale, saving them with descriptive filenames.

"""

import os

# Assuming the videos are named allen_screen_scaled_X.Y.mp4 where X.Y are the scale values
video_files_temporal = [f"allen_screen_scaled_{scale:.1f}.mp4" for scale in scale_values]

# Optional: Check if files exist
# for video_file in video_files_temporal:
#     if not os.path.exists(video_file):
#         print(f"Warning: Video file not found: {video_file}")

print("Defined the list of video files for temporal analysis.")

for scale in scale_values:
    filename = f"allen_screen_scaled_{scale:.1f}.mp4"
    print(f"Generating zebra noise for scale={scale:.1f} into {filename}...")
    zebranoise.zebra_noise(filename, xsize=1068, ysize=845, tdur=200/30, levels=10, xyscale=.2, tscale=50,fps=30, seed=0, xscale=scale, yscale=scale)
    print(f"Finished generating {filename}")

"""## Process and analyze FFT of all videos

"""

analysis_results = []

for scale in scale_values:
    video_path = f"allen_screen_scaled_{scale:.1f}.mp4"
    label = f"xscale={scale:.1f}"

    print(f"Processing and analyzing: {video_path}")

    # Process and analyze the video using the defined function
    (average_magnitude_spectrum, exclude_axes_mask,
     rows, cols) = process_and_average_spectrum(video_path)

    # Calculate spatial frequencies in cycles/pixel relative to the center
    spatial_freq_rows_centered = np.fft.fftshift(np.fft.fftfreq(rows))
    spatial_freq_cols_centered = np.fft.fftshift(np.fft.fftfreq(cols))

    # Create 2D arrays of centered frequency values
    spatial_freq_cols_2d_centered, spatial_freq_rows_2d_centered = np.meshgrid(spatial_freq_cols_centered, spatial_freq_rows_centered)

    # Convert radial frequency from cycles/pixel to cycles/degree
    # Use the degrees_per_pixel_v and degrees_per_pixel_h variables already calculated
    radial_freq_cpd = np.sqrt((spatial_freq_rows_2d_centered / degrees_per_pixel_v)**2 + (spatial_freq_cols_2d_centered / degrees_per_pixel_h)**2)

    # Flatten the radial frequencies and the average magnitude spectrum
    radial_freq_cpd_flat = radial_freq_cpd.flatten()
    average_magnitude_spectrum_flat = average_magnitude_spectrum.flatten()

    # Apply the exclusion mask to the flattened arrays
    radial_freq_cpd_filtered = radial_freq_cpd_flat[exclude_axes_mask]
    average_magnitude_spectrum_filtered = average_magnitude_spectrum_flat[exclude_axes_mask]

    # Calculate the radial average using the defined function
    bin_centers, average_magnitude_per_bin = calculate_radial_average(
        radial_freq_cpd_filtered, average_magnitude_spectrum_filtered
    )

    # Store the results
    analysis_results.append({
        "scale": scale,
        "label": label,
        "bin_centers": bin_centers,
        "average_magnitude_per_bin": average_magnitude_per_bin
    })

    print(f"Finished processing: {video_path}")

print("\nAll videos processed and analyzed.")

"""## Plot all radial spectra"""

plt.figure(figsize=(10, 6))

for result in analysis_results:
    plt.plot(result["bin_centers"], result["average_magnitude_per_bin"], '.', label=result["label"])

plt.yscale('log')
plt.xscale('log')
plt.xlim([0.01, 0.1])
plt.xlabel('Spatial Frequency (cycles/degree)')
plt.ylabel('Average Magnitude')
plt.title('Comparison of Average Radial Magnitude Spectra')
plt.legend()
plt.grid(True, which="both", ls="--")
plt.show()

"""## Define a function for temporal fourier transform


"""

import numpy as np
import imageio
from scipy.fft import fft

def compute_temporal_spectrum(video_path):
    """
    Computes the average temporal magnitude spectrum of a video across a few
    randomly selected pixels.

    Args:
        video_path (str): The path to the video file.

    Returns:
        tuple: A tuple containing:
            - temporal_frequencies (np.ndarray): The temporal frequencies in Hz.
            - average_temporal_magnitude_spectrum (np.ndarray): The average
                                                           magnitude spectrum.
    """
    video_reader = imageio.get_reader(video_path)

    # Get video properties
    meta_data = video_reader.get_meta_data()
    fps = meta_data.get('fps', 30) # Default to 30 fps if not found

    # Get dimensions from the first frame
    first_frame = video_reader.get_data(0)
    rows, cols = first_frame.shape[:2]

    # Select a small number of random pixel locations
    num_pixels_to_sample = 1000
    row_indices = np.random.randint(0, rows, num_pixels_to_sample)
    col_indices = np.random.randint(0, cols, num_pixels_to_sample)
    pixel_locations = list(zip(row_indices, col_indices))

    # Store time series data for selected pixels
    pixel_time_series = []

    for frame in video_reader:
        # Convert frame to grayscale
        if frame.ndim == 3:
            grayscale_frame = np.mean(frame, axis=2)
        else:
            grayscale_frame = frame

        # Extract intensity values at selected pixel locations for the current frame
        frame_intensities = [grayscale_frame[r, c] for r, c in pixel_locations]
        pixel_time_series.append(frame_intensities)

    # Convert time series data to a NumPy array (pixels x time)
    pixel_time_series_np = np.array(pixel_time_series).T # Transpose to have shape (num_pixels, num_frames)

    # Compute temporal Fourier transform for each pixel
    temporal_spectra = []
    for pixel_ts in pixel_time_series_np:
        f_transform = fft(pixel_ts)
        f_transform_shifted = np.fft.fftshift(f_transform)
        temporal_spectra.append(np.abs(f_transform_shifted))

    # Compute the average magnitude spectrum across pixels
    average_temporal_magnitude_spectrum = np.mean(temporal_spectra, axis=0)

    # Calculate corresponding temporal frequencies
    num_frames = pixel_time_series_np.shape[1]
    temporal_frequencies = np.fft.fftfreq(num_frames, d=1/fps)
    temporal_frequencies_shifted = np.fft.fftshift(temporal_frequencies)

    return temporal_frequencies_shifted, average_temporal_magnitude_spectrum

print("Defined the function compute_temporal_spectrum.")

"""## Apply the function to one video

### Subtask:
Call the newly defined function with the path to one of the generated videos (e.g., "allen_screen.mp4").

**Reasoning**:
Call the `compute_temporal_spectrum` function with the specified video path and store the results.
"""

# Call the function with the path to allen_screen.mp4
temporal_frequencies, average_temporal_magnitude_spectrum = compute_temporal_spectrum("/content/allen_screen.mp4")

print("Computed temporal spectrum for allen_screen.mp4")
print("Temporal frequencies shape:", temporal_frequencies.shape)
print("Average temporal magnitude spectrum shape:", average_temporal_magnitude_spectrum.shape)

"""## Visualize the temporal spectrum"""

import matplotlib.pyplot as plt
import numpy as np # Import numpy if not already imported in this cell

# Find the indices corresponding to positive frequencies (including 0)
positive_freq_indices = temporal_frequencies >= 0

# Select the positive frequencies and the corresponding magnitude spectrum values
positive_temporal_frequencies = temporal_frequencies[positive_freq_indices]
positive_average_temporal_magnitude_spectrum = average_temporal_magnitude_spectrum[positive_freq_indices]

# Sort the positive frequencies and magnitudes for proper plotting
# This is important because fftshift might not order the positive frequencies monotonically
sort_indices = np.argsort(positive_temporal_frequencies)
positive_temporal_frequencies_sorted = positive_temporal_frequencies[sort_indices]
positive_average_temporal_magnitude_spectrum_sorted = positive_average_temporal_magnitude_spectrum[sort_indices]


# Plot the average temporal magnitude spectrum (one side)
plt.figure(figsize=(10, 6))
plt.plot(positive_temporal_frequencies_sorted, positive_average_temporal_magnitude_spectrum_sorted)
plt.yscale('log')
plt.xlabel('Temporal Frequency (Hz)')
plt.ylabel('Average Magnitude')
plt.title('Average Temporal Magnitude Spectrum (Positive Frequencies)')
plt.grid(True)
plt.show()

"""## Define a list of tscale values

"""

import numpy as np

# Define a list of tscale values to experiment with
# Include the original value (50) and lower values to increase temporal frequency
tscale_values = [50, 40, 30, 20, 10]

print(tscale_values)

"""## Generate videos with varying tscale"""

for tscale in tscale_values:
    filename = f"allen_screen_tscale_{tscale}.mp4"
    print(f"Generating zebra noise for tscale={tscale} into {filename}...")
    zebranoise.zebra_noise(filename, xsize=1068, ysize=845, tdur=200/30, levels=10, xyscale=.2, tscale=tscale, fps=30, seed=0, xscale=1, yscale=1)
    print(f"Finished generating {filename}")

"""## Process and analyze temporal spectrum for all videos

"""

temporal_analysis_results = []

# Define a list of video file paths based on the tscale_values list
video_files_temporal = [f"allen_screen_tscale_{tscale}.mp4" for tscale in tscale_values]

# Iterate through the list of video file paths
for video_path in video_files_temporal:
    # Extract the tscale value from the filename
    # Assuming filename format is "allen_screen_tscale_XX.mp4"
    try:
        tscale_str = video_path.split('_')[-1].split('.')[0]
        current_tscale = int(tscale_str)
    except (IndexError, ValueError):
        print(f"Could not extract tscale from filename: {video_path}. Skipping.")
        continue

    print(f"Computing temporal spectrum for: {video_path} (tscale={current_tscale})")

    # Call the compute_temporal_spectrum function
    temporal_frequencies, average_temporal_magnitude_spectrum = compute_temporal_spectrum(video_path)

    # Store the results
    analysis_result = {
        "tscale": current_tscale,
        "temporal_frequencies": temporal_frequencies,
        "average_temporal_magnitude_spectrum": average_temporal_magnitude_spectrum
    }

    # Append the dictionary to the temporal_analysis_results list
    temporal_analysis_results.append(analysis_result)

print("\nTemporal analysis for all videos is complete.")

"""## Plot all temporal spectra"""

plt.figure(figsize=(10, 6))

for result in temporal_analysis_results:
    tscale = result["tscale"]
    temporal_frequencies = result["temporal_frequencies"]
    average_temporal_magnitude_spectrum = result["average_temporal_magnitude_spectrum"]

    # Find the indices corresponding to positive frequencies (including 0)
    positive_freq_indices = temporal_frequencies >= 0

    # Select the positive frequencies and the corresponding magnitude spectrum values
    positive_temporal_frequencies = temporal_frequencies[positive_freq_indices]
    positive_average_temporal_magnitude_spectrum = average_temporal_magnitude_spectrum[positive_freq_indices]

    # Sort the positive frequencies and magnitudes for proper plotting
    sort_indices = np.argsort(positive_temporal_frequencies)
    positive_temporal_frequencies_sorted = positive_temporal_frequencies[sort_indices]
    positive_average_temporal_magnitude_spectrum_sorted = positive_average_temporal_magnitude_spectrum[sort_indices]

    # Plot the average temporal magnitude spectrum (one side)
    plt.plot(positive_temporal_frequencies_sorted, positive_average_temporal_magnitude_spectrum_sorted, label=f"tscale={tscale}")

plt.yscale('log')
plt.xlabel('Temporal Frequency (Hz)')
plt.ylabel('Average Magnitude')
plt.title('Comparison of Average Temporal Magnitude Spectra')
plt.legend()
plt.grid(True)
plt.show()

"""## Play all generated videos

"""

from IPython.display import Video
import os

# Define a list of video file paths based on the tscale_values list
# Assuming the videos are named allen_screen_tscale_XX.mp4 where XX are the tscale values
video_files_temporal = [f"allen_screen_tscale_{tscale}.mp4" for tscale in tscale_values]

for video_path in video_files_temporal:
    if os.path.exists(video_path):
        print(f"Displaying video: {video_path}")
        display(Video(video_path, embed=True))
    else:
        print(f"Video file not found: {video_path}")

print("\nFinished displaying all generated videos.")

# Generate the final 5-minute video
print("Generating final 5-minute video...")
# 5 minutes * 60 seconds/minute * 30 frames/second
tdur_final = 5 * 60
zebranoise.zebra_noise("final_allen_screen_tscale_30_scale_1.0.mp4",
                       xsize=1068, ysize=845, tdur=tdur_final, levels=10,
                       xyscale=.2, tscale=30, fps=30, seed=0, xscale=1.0, yscale=1.0)
print("Finished generating final video.")